{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Example Feature Extraction from XML Files\n",
    "# We count the number of specific system calls made by the programs, and use\n",
    "# these as our features.\n",
    "\n",
    "# This code requires that the unzipped training set is in a folder called \"train\". \n",
    "\n",
    "import os\n",
    "from collections import Counter\n",
    "try:\n",
    "    import xml.etree.cElementTree as ET\n",
    "except ImportError:\n",
    "    import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "import util\n",
    "\n",
    "TRAIN_DIR = \"train\"\n",
    "\n",
    "call_set = set([])\n",
    "\n",
    "def add_to_set(tree):\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        call_set.add(call)\n",
    "\n",
    "def create_data_matrix(start_index, end_index, direc=\"train\"):\n",
    "    X = None\n",
    "    classes = []\n",
    "    ids = [] \n",
    "    i = -1\n",
    "    for datafile in os.listdir(direc):\n",
    "        if datafile == '.DS_Store':\n",
    "            continue\n",
    "\n",
    "        i += 1\n",
    "        if i < start_index:\n",
    "            continue \n",
    "        if i >= end_index:\n",
    "            break\n",
    "\n",
    "        # extract id and true class (if available) from filename\n",
    "        id_str, clazz = datafile.split('.')[:2]\n",
    "        ids.append(id_str)\n",
    "        # add target class if this is training data\n",
    "        try:\n",
    "            classes.append(util.malware_classes.index(clazz))\n",
    "\n",
    "        except ValueError:\n",
    "            # we should only fail to find the label in our list of malware classes\n",
    "            # if this is test data, which always has an \"X\" label\n",
    "            assert clazz == \"X\"\n",
    "            classes.append(-1)\n",
    "\n",
    "        # parse file as an xml document\n",
    "        tree = ET.parse(os.path.join(direc,datafile))\n",
    "        if direc==\"train\":\n",
    "            add_to_set(tree)\n",
    "        this_row = call_feats(tree)\n",
    "        if X is None:\n",
    "            X = this_row \n",
    "        else:\n",
    "            X = np.vstack((X, this_row))\n",
    "\n",
    "    return X, np.array(classes), ids\n",
    "\n",
    "def call_feats(tree):\n",
    "    good_calls = ['sleep', 'dump_line']\n",
    "\n",
    "    call_counter = {}\n",
    "    for el in tree.iter():\n",
    "        call = el.tag\n",
    "        if call not in call_counter:\n",
    "            call_counter[call] = 1\n",
    "        else:\n",
    "            call_counter[call] += 1\n",
    "\n",
    "    call_feat_array = np.zeros(len(good_calls))\n",
    "    for i in range(len(good_calls)):\n",
    "        call = good_calls[i]\n",
    "        call_feat_array[i] = 0\n",
    "        if call in call_counter:\n",
    "            call_feat_array[i] = call_counter[call]\n",
    "\n",
    "    return call_counter\n",
    "\n",
    "# # Feature extraction\n",
    "# def main():\n",
    "#     X_train, t_train, train_ids = create_data_matrix(0, 5, TRAIN_DIR)\n",
    "#     X_valid, t_valid, valid_ids = create_data_matrix(10, 15, TRAIN_DIR)\n",
    "\n",
    "#     print 'Data matrix (training set):'\n",
    "#     print X_train\n",
    "#     print 'Classes (training set):'\n",
    "#     print t_train\n",
    "\n",
    "#     # From here, you can train models (eg by importing sklearn and inputting X_train, t_train).\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, t_train, train_ids = create_data_matrix(0, 3086, TRAIN_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test, t_test, test_ids = create_data_matrix(0, 3728, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertMatrix(X, call_set):\n",
    "    features = dict()\n",
    "    for i in call_set:\n",
    "        features[i] = []\n",
    "    \n",
    "    for i in X:\n",
    "        for j in call_set:\n",
    "            if j in i[0].keys():\n",
    "                features[j].append(i[0][j])\n",
    "            else:\n",
    "                features[j].append(0)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = pd.DataFrame(convertMatrix(X_train,call_set))\n",
    "test_set= pd.DataFrame(convertMatrix(X_test,call_set))\n",
    "# train_set['id'] = train_ids\n",
    "# train_set['class'] = t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_set['id'] = train_ids\n",
    "train_set['class'] = t_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_set['id'] = test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_eng_dir = 'train/'\n",
    "id_list_feat_eng = []\n",
    "hash_error_list_feat_eng = []\n",
    "security_anony_list_feat_eng = []\n",
    "class_list_feat_eng = []\n",
    "for file_name in os.listdir('train/'):\n",
    "    if file_name == '.DS_Store':\n",
    "        continue\n",
    "    content = open(feature_eng_dir + file_name, 'r').read()\n",
    "    num_of_line = content.count('<')\n",
    "    num_of_hash_error = content.count('hash_error')\n",
    "    num_of_security_anony = content.count('SECURITY_ANONYMOUS')\n",
    "    class_list_feat_eng.append(file_name.split('.')[1])\n",
    "    \n",
    "    id_list_feat_eng.append(file_name.split('.')[0])\n",
    "    hash_error_list_feat_eng.append(1.0*num_of_hash_error/num_of_line)\n",
    "    security_anony_list_feat_eng.append(1.0*num_of_security_anony/num_of_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "train_set_2=copy.deepcopy(train_set)\n",
    "train_set_2['id'] =train_ids\n",
    "feat_eng_df = pd.DataFrame({'id':id_list_feat_eng, 'hash_error':hash_error_list_feat_eng, 'security_anonymous':security_anony_list_feat_eng})\n",
    "new=pd.merge(train_set_2, feat_eng_df, on='id')\n",
    "new=new.drop('id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats.stats import pearsonr   \n",
    "b=new['security_anonymous'].values\n",
    "type(t_train)\n",
    "pearsonr(t_train,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\",\"Poly SVM\",\"Sigmoid SVM\",\"RBF SVM\", \"Decision Tree\",\n",
    "         \"Random Forest\",  \"Linear Discriminant Analysis\",\n",
    "         \"Quadratic Discriminant Analysis\"]\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(5),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(kernel=\"poly\", C=0.025),\n",
    "    SVC(kernel=\"sigmoid\", C=0.025),\n",
    "    SVC(kernel=\"rbf\",C=0.025),\n",
    "    #SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=10),\n",
    "    RandomForestClassifier(max_depth=10, n_estimators=10, max_features=1),\n",
    "    #AdaBoostClassifier(),\n",
    "    #GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = t_train\n",
    "X_train = train_set.drop(['id', 'class'], axis = 1)\n",
    "# y_valid = t_train\n",
    "# X_valid = train_set[2000:].drop(['id', 'class'], axis = 1)\n",
    "y_test = t_test\n",
    "X_test = test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1, -1, -1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Neighbors 0.837937384899\n",
      "Linear SVM 0.85635359116\n",
      "Poly SVM 0.82320441989\n",
      "Sigmoid SVM 0.515653775322\n",
      "RBF SVM 0.622467771639\n",
      "Decision Tree 0.858195211786\n",
      "Random Forest"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:453: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n",
      "//anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.883057090239\n",
      "Linear Discriminant Analysis 0.830570902394\n",
      "Quadratic Discriminant Analysis 0.791896869245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python2.7/site-packages/sklearn/discriminant_analysis.py:688: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "for name, clf in zip(names, classifiers):\n",
    "#         ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_valid, y_valid)\n",
    "        print name, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87476979742173111"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                                 max_depth=5, random_state=2).fit(X_train, y_train)\n",
    "clf.score(X_valid, y_valid)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'learning_rate': 0.1, 'random_state': 1} 0.876388888889 [mean: 0.87037, std: 0.01682, params: {'learning_rate': 0.01, 'random_state': 1}, mean: 0.87083, std: 0.01647, params: {'learning_rate': 0.01, 'random_state': 2}, mean: 0.87037, std: 0.01684, params: {'learning_rate': 0.01, 'random_state': 3}, mean: 0.87037, std: 0.01689, params: {'learning_rate': 0.01, 'random_state': 5}, mean: 0.87639, std: 0.01698, params: {'learning_rate': 0.1, 'random_state': 1}, mean: 0.87500, std: 0.01534, params: {'learning_rate': 0.1, 'random_state': 2}, mean: 0.87639, std: 0.01484, params: {'learning_rate': 0.1, 'random_state': 3}, mean: 0.87639, std: 0.01439, params: {'learning_rate': 0.1, 'random_state': 5}, mean: 0.87176, std: 0.01227, params: {'learning_rate': 0.2, 'random_state': 1}, mean: 0.86991, std: 0.01487, params: {'learning_rate': 0.2, 'random_state': 2}, mean: 0.87130, std: 0.01569, params: {'learning_rate': 0.2, 'random_state': 3}, mean: 0.87222, std: 0.01500, params: {'learning_rate': 0.2, 'random_state': 5}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.98\n",
      "Accuracy on test data:     0.90\n",
      "[[ 16   0   0   0   0   0   0   1  14   0   2   1   1   0   0]\n",
      " [  0   7   0   2   0   0   0   0   1   1   0   0   4   1   0]\n",
      " [  0   0  10   0   0   1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1  10   0   1   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   8   0   0   0   4   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   5   0   0   2   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0  12   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   8   1   0   0   0   0   0   0]\n",
      " [  3   0   1   0   2   0   0   1 486   0   3   1   4   2   1]\n",
      " [  0   0   0   0   0   0   0   0   1   1   3   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   1   0   0   8   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   3   1   0   0 102   0   0]\n",
      " [  1   0   0   0   0   0   0   0  10   0   0   0   1   7   0]\n",
      " [  1   0   0   0   0   0   0   0   3   0   0   0   0   0  12]]\n",
      "########################################################\n",
      "CPU times: user 17min 46s, sys: 44.4 s, total: 18min 30s\n",
      "Wall time: 18min 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clfrf, Xtrain, ytrain, Xtest, ytest = do_classify(GradientBoostingClassifier(),\n",
    "                                                   {\"learning_rate\": [0.01,0.1,0.2],\n",
    "                                                    \"random_state\":[1,2,3, 5]}, \n",
    "                                                   X_train,t_train,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_test=clfrf.predict(X_test)\n",
    "write_predictions(t_test,test_ids,\"gradient.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier(max_depth=10, n_estimators=10, max_features=1)\n",
    "clf.fit(train_set, t_train)\n",
    "t_test=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# these are the fifteen malware classes we're looking for\n",
    "malware_classes = [\"Agent\", \"AutoRun\", \"FraudLoad\", \"FraudPack\", \"Hupigon\", \"Krap\",\n",
    "           \"Lipler\", \"Magania\", \"None\", \"Poison\", \"Swizzor\", \"Tdss\",\n",
    "           \"VB\", \"Virut\", \"Zbot\"]\n",
    "\n",
    "# a function for writing predictions in the required format\n",
    "def write_predictions(predictions, ids, outfile):\n",
    "    \"\"\"\n",
    "    assumes len(predictions) == len(ids), and that predictions[i] is the\n",
    "    index of the predicted class with the malware_classes list above for \n",
    "    the executable corresponding to ids[i].\n",
    "    outfile will be overwritten\n",
    "    \"\"\"\n",
    "    with open(outfile,\"w+\") as f:\n",
    "        # write header\n",
    "        f.write(\"Id,Prediction\\n\")\n",
    "        for i, history_id in enumerate(ids):\n",
    "            f.write(\"%s,%d\\n\" % (history_id, predictions[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_predictions(t_test,test_ids,\"randomforrest.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Generate a large random dataset\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = train_set.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3,\n",
    "            square=True, xticklabels=5, yticklabels=5,\n",
    "            linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.91315276e-01,   2.63259786e-01,   1.45155855e-01,\n",
       "         9.41070436e-02,   4.22026597e-02,   1.50369668e-02,\n",
       "         1.35901802e-02,   1.08299298e-02,   9.02474844e-03,\n",
       "         4.79322777e-03,   3.51131656e-03,   1.46616478e-03,\n",
       "         1.30781114e-03,   1.09285478e-03,   8.78713852e-04,\n",
       "         4.77860237e-04,   4.44813602e-04,   3.01532820e-04,\n",
       "         2.17952089e-04,   1.66558047e-04])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca=PCA(n_components=20)\n",
    "pca.fit_transform(train_set,t_train)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_train=pca.fit_transform(train_set,t_train)\n",
    "pca_test=pca.transform(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systemized Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(train_set.shape[0]), train_size=0.7,random_state=123)\n",
    "mask=np.ones(train_set.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "\"\"\"\n",
    "Function\n",
    "--------\n",
    "cv_optimize\n",
    "\n",
    "Inputs\n",
    "------\n",
    "clf : an instance of a scikit-learn classifier\n",
    "parameters: a parameter grid dictionary thats passed to GridSearchCV (see above)\n",
    "X: a samples-features matrix in the scikit-learn style\n",
    "y: the response vectors of 1s and 0s (+ives and -ives)\n",
    "n_folds: the number of cross-validation folds (default 5)\n",
    "score_func: a score function we might want to pass (default python None)\n",
    "   \n",
    "Returns\n",
    "-------\n",
    "The best estimator from the GridSearchCV, after the GridSearchCV has been used to\n",
    "fit the model.\n",
    "     \n",
    "Notes\n",
    "-----\n",
    "see do_classify and the code below for an example of how this is used\n",
    "\"\"\"\n",
    "#your code here\n",
    "\n",
    "def cv_optimize(clf,parameters,X,y,n_folds,score_func=None):\n",
    "    if score_func:\n",
    "        fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds, scoring=score_func)\n",
    "    else:\n",
    "        fitmodel = GridSearchCV(clf, param_grid=parameters, cv=n_folds)\n",
    "    fitmodel.fit(X,y)\n",
    "    print \"BEST\", fitmodel.best_params_, fitmodel.best_score_, fitmodel.grid_scores_\n",
    "    best = fitmodel.best_estimator_\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def do_classify(clf, parameters, train, test, mask=None, reuse_split=None, score_func=None, n_folds=5):\n",
    "    \n",
    "    X=train\n",
    "    y=test\n",
    "    if mask !=None:\n",
    "        print \"using mask\"\n",
    "        Xtrain, Xtest, ytrain, ytest = X[mask], X[~mask], y[mask], y[~mask]\n",
    "    if reuse_split !=None:\n",
    "        print \"using reuse split\"\n",
    "        Xtrain, Xtest, ytrain, ytest = reuse_split['Xtrain'], reuse_split['Xtest'], reuse_split['ytrain'], reuse_split['ytest']\n",
    "    if parameters:\n",
    "        clf = cv_optimize(clf, parameters, Xtrain, ytrain, n_folds=n_folds, score_func=score_func)\n",
    "    clf=clf.fit(Xtrain, ytrain)\n",
    "    training_accuracy = clf.score(Xtrain, ytrain)\n",
    "    test_accuracy = clf.score(Xtest, ytest)\n",
    "    print \"############# based on standard predict ################\"\n",
    "    print \"Accuracy on training data: %0.2f\" % (training_accuracy)\n",
    "    print \"Accuracy on test data:     %0.2f\" % (test_accuracy)\n",
    "    print confusion_matrix(ytest, clf.predict(Xtest))\n",
    "    print \"########################################################\"\n",
    "    return clf, Xtrain, ytrain, Xtest, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clfrf, Xtrain, ytrain, Xtest, ytest = do_classify(RandomForestClassifier(),\n",
    "                                                   {\"max_depth\": [10,20,50,100,200,500]}, \n",
    "                                                   train_set,t_train,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_test=clfrf.predict(X_test)\n",
    "write_predictions(t_test,test_ids,\"randomforrest2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'n_estimators': 50, 'max_depth': 20} 0.883333333333 [mean: 0.83380, std: 0.01164, params: {'n_estimators': 1, 'max_depth': 10}, mean: 0.87083, std: 0.01103, params: {'n_estimators': 5, 'max_depth': 10}, mean: 0.87454, std: 0.01100, params: {'n_estimators': 10, 'max_depth': 10}, mean: 0.87593, std: 0.01088, params: {'n_estimators': 20, 'max_depth': 10}, mean: 0.87917, std: 0.01683, params: {'n_estimators': 50, 'max_depth': 10}, mean: 0.84074, std: 0.00589, params: {'n_estimators': 1, 'max_depth': 20}, mean: 0.86620, std: 0.00570, params: {'n_estimators': 5, 'max_depth': 20}, mean: 0.87824, std: 0.01279, params: {'n_estimators': 10, 'max_depth': 20}, mean: 0.87546, std: 0.00940, params: {'n_estimators': 20, 'max_depth': 20}, mean: 0.88333, std: 0.01391, params: {'n_estimators': 50, 'max_depth': 20}, mean: 0.82870, std: 0.00936, params: {'n_estimators': 1, 'max_depth': 50}, mean: 0.86713, std: 0.00693, params: {'n_estimators': 5, 'max_depth': 50}, mean: 0.87639, std: 0.01031, params: {'n_estimators': 10, 'max_depth': 50}, mean: 0.87917, std: 0.00472, params: {'n_estimators': 20, 'max_depth': 50}, mean: 0.88102, std: 0.01254, params: {'n_estimators': 50, 'max_depth': 50}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.99\n",
      "Accuracy on test data:     0.91\n",
      "[[ 19   0   0   0   1   0   0   1  13   0   1   0   0   0   0]\n",
      " [  0   9   0   0   0   0   0   0   1   1   1   0   4   0   0]\n",
      " [  0   0  10   0   0   1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  11   0   1   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   6   0   0   0   6   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   5   0   0   2   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0  12   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   8   2   0   0   0   0   0   0]\n",
      " [  5   0   0   0   1   0   0   0 489   0   3   1   3   2   0]\n",
      " [  0   0   0   0   0   0   0   0   2   1   2   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   8   0   0   0]\n",
      " [  1   0   0   0   0   1   0   0   5   1   0   0  99   0   0]\n",
      " [  3   0   0   0   0   0   0   0   9   0   0   0   1   6   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0   0   0   0   2  13]]\n",
      "########################################################\n",
      "CPU times: user 5.3 s, sys: 35.2 ms, total: 5.33 s\n",
      "Wall time: 5.37 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clfrf, Xtrain, ytrain, Xtest, ytest = do_classify(RandomForestClassifier(random_state=123),\n",
    "                                                   {\"max_depth\": [10,20,50],\n",
    "                                                    \"n_estimators\":[1,5,10,20,50]}, \n",
    "                                                   train_set,t_train,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-0bda216bf536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreuse_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mytest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "reuse_split=dict(Xtrain=Xtrain, Xtest=Xtest, ytrain=ytrain, ytest=ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ffdba6079b981688512353cF89ca7e1b8f4868263",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-ab1bd6fc3505>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'from sklearn.linear_model import LogisticRegression \\n\\nclflr, Xtrain, ytrain, Xtest, ytest = do_classify(LogisticRegression(penalty=\"l2\",random_state=12,\\\\\\n                                                                     multi_class=\"multinomial\",class_weight=\\'balanced\\'), \\\\\\n                                                   {\"C\": [0.01, 0.1, 1.0, 10.0],\"solver\":[\"newton-cg\"]},\\n                                                   train_set,t_train,mask=mask)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2291\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2293\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2294\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-64bbf4bd576d>\u001b[0m in \u001b[0;36mdo_classify\u001b[0;34m(clf, parameters, train, test, mask, reuse_split, score_func, n_folds)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Xtrain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Xtest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ytrain'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ytest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv_optimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mclf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtraining_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-010af85d96de>\u001b[0m in \u001b[0;36mcv_optimize\u001b[0;34m(clf, parameters, X, y, n_folds, score_func)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mfitmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"BEST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfitmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m         \"\"\"\n\u001b[0;32m--> 804\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/grid_search.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, parameter_iterable)\u001b[0m\n\u001b[1;32m    551\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m                                     error_score=self.error_score)\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparameter_iterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 for train, test in cv)\n\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    798\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    656\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pool\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateComputeBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1531\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1532\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1533\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=np.float64, \n\u001b[0;32m-> 1142\u001b[0;31m                          order=\"C\")\n\u001b[0m\u001b[1;32m   1143\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    508\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    509\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    371\u001b[0m                                       force_all_finite)\n\u001b[1;32m    372\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m         \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ffdba6079b981688512353cF89ca7e1b8f4868263"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "clflr, Xtrain, ytrain, Xtest, ytest = do_classify(LogisticRegression(penalty=\"l2\",random_state=12,\\\n",
    "                                                                     multi_class=\"multinomial\",class_weight='balanced'), \\\n",
    "                                                   {\"C\": [0.01, 0.1, 1.0, 10.0],\"solver\":[\"newton-cg\"]},\n",
    "                                                   train_set,t_train,mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_test=clflr.predict(test_set)\n",
    "write_predictions(t_test,test_ids,\"logistic2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# clfnn, Xtrain, ytrain, Xtest, ytest = do_classify(MLPClassifier(algorithm=\"sgd\",activation=\"logistic\",\n",
    "#                                                                random_state=1),\n",
    "#                                                    {\"alpha\": [1e-5,1e-4,1e-3,1e-2,1],\n",
    "#                                                     \"n_estimators\":[1,5,10]}, \n",
    "#                                                    train_set,t_train,reuse_split=reuse_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "itrain, itest = train_test_split(xrange(pca_train.shape[0]), train_size=0.7)\n",
    "mask=np.ones(pca_train.shape[0], dtype='int')\n",
    "mask[itrain]=1\n",
    "mask[itest]=0\n",
    "mask = (mask==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'n_estimators': 50, 'max_depth': 20} 0.869907407407 [mean: 0.81898, std: 0.01532, params: {'n_estimators': 1, 'max_depth': 10}, mean: 0.85324, std: 0.00982, params: {'n_estimators': 5, 'max_depth': 10}, mean: 0.85972, std: 0.00693, params: {'n_estimators': 10, 'max_depth': 10}, mean: 0.86157, std: 0.00596, params: {'n_estimators': 20, 'max_depth': 10}, mean: 0.86944, std: 0.01028, params: {'n_estimators': 50, 'max_depth': 10}, mean: 0.82269, std: 0.02251, params: {'n_estimators': 1, 'max_depth': 20}, mean: 0.84769, std: 0.01220, params: {'n_estimators': 5, 'max_depth': 20}, mean: 0.85741, std: 0.01079, params: {'n_estimators': 10, 'max_depth': 20}, mean: 0.86435, std: 0.01150, params: {'n_estimators': 20, 'max_depth': 20}, mean: 0.86991, std: 0.01455, params: {'n_estimators': 50, 'max_depth': 20}, mean: 0.82269, std: 0.02251, params: {'n_estimators': 1, 'max_depth': 50}, mean: 0.84722, std: 0.01164, params: {'n_estimators': 5, 'max_depth': 50}, mean: 0.85648, std: 0.01106, params: {'n_estimators': 10, 'max_depth': 50}, mean: 0.86065, std: 0.01055, params: {'n_estimators': 20, 'max_depth': 50}, mean: 0.86806, std: 0.01448, params: {'n_estimators': 50, 'max_depth': 50}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.99\n",
      "Accuracy on test data:     0.88\n",
      "[[ 15   0   0   0   0   0   0   1  17   0   2   0   0   0   0]\n",
      " [  0   7   0   0   0   0   0   0   2   1   1   0   4   1   0]\n",
      " [  0   0   9   1   0   1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   9   0   1   0   0   3   0   0   0   0   0   0]\n",
      " [  0   0   0   0   2   0   0   0  11   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   6   0   0   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  10   0   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   8   1   0   1   0   0   0   0]\n",
      " [  8   0   0   0   0   0   1   0 480   1   3   1   7   2   1]\n",
      " [  0   0   0   0   0   0   0   0   3   1   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   0   8   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   7   1   0   0  99   0   0]\n",
      " [  2   0   0   0   0   0   0   0   9   0   0   0   1   7   0]\n",
      " [  4   0   0   0   0   0   0   0   2   0   0   0   0   0  10]]\n",
      "########################################################\n",
      "CPU times: user 8.31 s, sys: 57.4 ms, total: 8.36 s\n",
      "Wall time: 8.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clfrf, Xtrain, ytrain, Xtest, ytest = do_classify(RandomForestClassifier(random_state=123),\n",
    "                                                   {\"max_depth\": [10,20,50],\n",
    "                                                    \"n_estimators\":[1,5,10,20,50]}, \n",
    "                                                   pca_train,t_train,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using reuse split\n",
      "BEST {'C': 1.0, 'solver': 'newton-cg'} 0.855555555556 [mean: 0.66389, std: 0.00949, params: {'C': 0.01, 'solver': 'sag'}, mean: 0.84954, std: 0.01880, params: {'C': 0.01, 'solver': 'newton-cg'}, mean: 0.66389, std: 0.00949, params: {'C': 0.1, 'solver': 'sag'}, mean: 0.85370, std: 0.01900, params: {'C': 0.1, 'solver': 'newton-cg'}, mean: 0.66389, std: 0.00949, params: {'C': 1.0, 'solver': 'sag'}, mean: 0.85556, std: 0.01823, params: {'C': 1.0, 'solver': 'newton-cg'}, mean: 0.66389, std: 0.00949, params: {'C': 10.0, 'solver': 'sag'}, mean: 0.85324, std: 0.02000, params: {'C': 10.0, 'solver': 'newton-cg'}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.92\n",
      "Accuracy on test data:     0.86\n",
      "[[ 14   0   0   0   0   2   0   1  13   1   0   0   3   0   1]\n",
      " [  0   9   0   0   0   0   0   0   0   2   0   0   5   0   0]\n",
      " [  0   0   4   3   0   2   0   0   2   0   0   0   0   0   0]\n",
      " [  0   0   2   5   0   4   0   0   2   0   0   0   0   0   0]\n",
      " [  0   1   1   0  10   0   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   5   0   0   2   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0  10   0   2   0   0   0   0   0   0]\n",
      " [  1   0   0   1   0   0   0   4   4   0   0   0   0   0   0]\n",
      " [  6   1   1   0   0   1   0   1 468   4   3   2  13   3   1]\n",
      " [  1   0   0   0   0   0   0   0   2   2   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   1   0   0   8   0   0   0]\n",
      " [  2   0   0   0   0   2   0   0   4   0   0   0  99   0   0]\n",
      " [  0   0   0   0   0   0   0   0  15   0   0   0   1   3   0]\n",
      " [  0   1   1   0   0   0   0   0   4   0   0   0   1   0   9]]\n",
      "########################################################\n",
      "CPU times: user 4min 32s, sys: 19.7 s, total: 4min 51s\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "clflr, Xtrain, ytrain, Xtest, ytest = do_classify(LogisticRegression(penalty=\"l2\",random_state=12,\\\n",
    "                                                                     multi_class=\"ovr\"), \\\n",
    "                                                   {\"C\": [0.01, 0.1, 1.0, 10.0],\"solver\":[\"sag\",\"newton-cg\"]},\n",
    "                                                   pca_train,t_train,reuse_split=reuse_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(call_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-6ccb9b9f18b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGaussianGenerativeModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misSharedCovariance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mcall_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mt_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcall_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Jing/Documents/Harvard/Course/CS181/Practicals/Practical2/GaussianGenerativeModel.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mmu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mN_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;31m#compute the MLE sigma both shared and not shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "from GaussianGenerativeModel import GaussianGenerativeModel\n",
    "\n",
    "nb1 = GaussianGenerativeModel(isSharedCovariance=False)\n",
    "nb1.fit(train_set.values,t_train)\n",
    "call_list=list(call_set)\n",
    "t_test=nb1.predict(test_set.values,call_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_predictions(t_test,test_ids,\"GMM2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb1 = GaussianGenerativeModel(isSharedCovariance=False)\n",
    "nb1.fit(pca_train,t_train)\n",
    "call_list=list(call_set)\n",
    "t_test=nb1.predict(pca_test,call_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kaggle score 0.65158"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.mixture import GMM\n",
    "\n",
    "# clflr, Xtrain, ytrain, Xtest, ytest = do_classify(GMM(covariance_type='diag',random_state=None,\n",
    "#                                                       n_components=15,n_iter=100), \\\n",
    "#                                                   {},pca_train,t_train,reuse_split=reuse_split)\n",
    "\n",
    "clfgmm=GMM(n_components=15)\n",
    "clfgmm.fit(pca_train[:2000],y=t_train[:2000])\n",
    "print np.average(clfgmm.score(pca_train[2000:],y=t_train[2000:]))\n",
    "\n",
    "clfgmm.fit(pca_train,y=t_train)\n",
    "t_test=clfgmm.predict(pca_test)\n",
    "write_predictions(t_test,test_ids,\"GMM.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using reuse split\n",
      "BEST {'kernel': 'linear', 'C': 0.01} 0.859259259259 [mean: 0.51157, std: 0.00456, params: {'kernel': 'sigmoid', 'C': 0.01}, mean: 0.82269, std: 0.01483, params: {'kernel': 'poly', 'C': 0.01}, mean: 0.55602, std: 0.03667, params: {'kernel': 'rbf', 'C': 0.01}, mean: 0.85926, std: 0.01660, params: {'kernel': 'linear', 'C': 0.01}, mean: 0.51157, std: 0.00456, params: {'kernel': 'sigmoid', 'C': 0.1}, mean: 0.81898, std: 0.01642, params: {'kernel': 'poly', 'C': 0.1}, mean: 0.67083, std: 0.01117, params: {'kernel': 'rbf', 'C': 0.1}, mean: 0.85463, std: 0.01729, params: {'kernel': 'linear', 'C': 0.1}, mean: 0.51157, std: 0.00456, params: {'kernel': 'sigmoid', 'C': 1.0}, mean: 0.81898, std: 0.01946, params: {'kernel': 'poly', 'C': 1.0}, mean: 0.77593, std: 0.00996, params: {'kernel': 'rbf', 'C': 1.0}, mean: 0.85833, std: 0.01218, params: {'kernel': 'linear', 'C': 1.0}, mean: 0.51157, std: 0.00456, params: {'kernel': 'sigmoid', 'C': 10.0}, mean: 0.81852, std: 0.01861, params: {'kernel': 'poly', 'C': 10.0}, mean: 0.78194, std: 0.01187, params: {'kernel': 'rbf', 'C': 10.0}, mean: 0.85093, std: 0.01939, params: {'kernel': 'linear', 'C': 10.0}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.93\n",
      "Accuracy on test data:     0.86\n",
      "[[ 14   0   1   1   0   0   1   1  13   0   1   0   2   0   1]\n",
      " [  0   8   0   1   0   0   0   0   1   0   1   0   5   0   0]\n",
      " [  0   0   5   2   0   1   0   0   3   0   0   0   0   0   0]\n",
      " [  2   0   0   8   0   1   0   0   2   0   0   0   0   0   0]\n",
      " [  1   0   0   0   7   0   0   0   4   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   5   0   0   2   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0  10   0   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   4   6   0   0   0   0   0   0]\n",
      " [  8   1   0   0   0   0   4   2 475   2   4   1   6   1   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   3   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   1   0   0   8   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   5   0   0   0 101   0   0]\n",
      " [  1   0   0   0   0   0   0   0  16   0   1   0   1   0   0]\n",
      " [  1   1   0   0   0   0   0   0   4   0   2   0   0   0   8]]\n",
      "########################################################\n",
      "CPU times: user 43min 38s, sys: 11.3 s, total: 43min 50s\n",
      "Wall time: 44min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clflsvm, Xtrain, ytrain, Xtest, ytest = do_classify(SVC(random_state=123), \\\n",
    "                                                   {\"C\": [0.01, 0.1, 1.0, 10.0],\"kernel\":[\"sigmoid\",\"poly\",\"rbf\",\"linear\"]},\n",
    "                                                   train_set,t_train,reuse_split=reuse_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using reuse split\n",
      "BEST {'kernel': 'linear', 'C': 0.001} 0.856481481481 [mean: 0.85648, std: 0.01585, params: {'kernel': 'linear', 'C': 0.001}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.90\n",
      "Accuracy on test data:     0.85\n",
      "[[ 12   0   1   0   0   1   1   1  15   0   2   0   1   0   1]\n",
      " [  0   7   0   1   0   0   0   0   1   0   2   0   5   0   0]\n",
      " [  1   0   6   0   0   1   0   0   3   0   0   0   0   0   0]\n",
      " [  0   0   0  10   0   1   0   0   2   0   0   0   0   0   0]\n",
      " [  1   0   0   0   2   0   0   0   7   0   0   0   3   0   0]\n",
      " [  0   0   0   0   0   5   0   0   2   0   0   0   0   0   1]\n",
      " [  0   0   0   0   0   0  10   0   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   4   6   0   0   0   0   0   0]\n",
      " [  7   2   0   0   0   3   2   1 467   0   4   1  17   0   0]\n",
      " [  0   0   0   0   0   0   0   0   2   0   3   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   2   0   0   7   0   0   0]\n",
      " [  1   0   0   0   0   1   0   0   6   0   0   0  99   0   0]\n",
      " [  0   0   0   0   0   0   0   0  17   0   0   0   1   1   0]\n",
      " [  2   1   0   0   0   0   0   0   4   0   2   0   0   0   7]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "clflsvm, Xtrain, ytrain, Xtest, ytest = do_classify(SVC(random_state=123), \\\n",
    "                                                   {\"C\": [0.001],\"kernel\":[\"linear\"]},\n",
    "                                                   train_set,t_train,reuse_split=reuse_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 106)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(call_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cfceeea896da8c14eb2fc96791ee98b33e843db03'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cfceeea896da8c14eb2fc96791ee98b33e843db03.VB.xml'.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whole_file_flow = dict()\n",
    "\n",
    "for datafile in os.listdir('train'):\n",
    "    if datafile == '.DS_Store':\n",
    "        continue\n",
    "        \n",
    "    file1_tag_flow = []\n",
    "    file1 = open('train/'+datafile, 'r')\n",
    "#     file1.readline()\n",
    "    for line in file1:\n",
    "        tag = line.split(' ')[0][1:]\n",
    "        if tag in list(call_set):\n",
    "            file1_tag_flow.append(tag)\n",
    "    \n",
    "    file1_tag_flow_unique = [file1_tag_flow[0]]\n",
    "    for i in range(1, len(file1_tag_flow)):\n",
    "        if file1_tag_flow[i] == file1_tag_flow_unique[-1]:\n",
    "            continue\n",
    "        else :\n",
    "            file1_tag_flow_unique.append(file1_tag_flow[i])\n",
    "        \n",
    "    whole_file_flow[datafile.split('.')[0]] = file1_tag_flow_unique\n",
    "# print file1_tag_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import itemfreq\n",
    "\n",
    "file_gram_pair = dict()\n",
    "\n",
    "for k in whole_file_flow.keys():\n",
    "    file1_tag_flow_unique = whole_file_flow[k]\n",
    "#     N = 4 # bi-grams\n",
    "    grams=[]\n",
    "#     for n in range(2,5):\n",
    "    n = 4\n",
    "    grams += [file1_tag_flow_unique[i:i+n] for i in xrange(len(file1_tag_flow_unique)-n)]\n",
    "    #print len(grams)\n",
    "    # ?itemfreq\n",
    "\n",
    "    single_key_grams = []\n",
    "    for i in grams:\n",
    "        single_key_grams.append(' '.join(i))\n",
    "        \n",
    "    grams = []\n",
    "    for i in list(itemfreq(single_key_grams)):\n",
    "        grams.append([i[0], int(i[1])])\n",
    "    grams.sort(key = lambda x: x[1], reverse = True) \n",
    "    file_gram_pair[k] = grams\n",
    "# print itemfreq(grams)\n",
    "\n",
    "# for i in file1_tag_flow_unique:\n",
    "#     for j in file1_tag_flow_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_features = []\n",
    "for v in file_gram_pair.values():\n",
    "    new_features += [i[0] for i in v if i[1] >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "itemfreq((new_features))\n",
    "feature = []\n",
    "for i in list(itemfreq((new_features))):\n",
    "    feature.append([i[0], int(i[1])])\n",
    "\n",
    "feature.sort(key = lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['open_key query_value open_key query_value',\n",
       " 'query_value open_key query_value open_key',\n",
       " 'vm_protect vm_write vm_allocate vm_protect',\n",
       " 'process thread load_image load_dll',\n",
       " 'dump_line trimmed_bytes recv_socket dump_line',\n",
       " 'recv_socket dump_line trimmed_bytes recv_socket',\n",
       " 'trimmed_bytes recv_socket dump_line trimmed_bytes',\n",
       " 'dump_line trimmed_bytes send_socket dump_line',\n",
       " 'open_key enum_keys open_key query_value',\n",
       " 'send_socket dump_line trimmed_bytes send_socket',\n",
       " 'open_key query_value load_dll create_window',\n",
       " 'trimmed_bytes send_socket dump_line trimmed_bytes',\n",
       " 'load_dll open_key query_value open_key',\n",
       " 'open_file open_key query_value open_file',\n",
       " 'open_file open_key query_value open_key',\n",
       " 'open_key query_value open_file find_file',\n",
       " 'query_value open_file find_file open_key',\n",
       " 'get_file_attributes read_value get_file_attributes read_value',\n",
       " 'open_key query_value load_dll open_key',\n",
       " 'read_value get_file_attributes read_value get_file_attributes',\n",
       " 'load_dll open_key load_dll open_key',\n",
       " 'create_window open_key query_value open_key',\n",
       " 'dump_line recv_socket dump_line trimmed_bytes',\n",
       " 'send_socket dump_line recv_socket dump_line',\n",
       " 'query_value set_value query_value set_value',\n",
       " 'open_key query_value open_file open_key',\n",
       " 'enum_keys open_key query_value open_key',\n",
       " 'bind_socket connect_socket send_socket dump_line',\n",
       " 'create_socket bind_socket connect_socket send_socket',\n",
       " 'set_value query_value set_value query_value',\n",
       " 'create_mutex open_key query_value open_key',\n",
       " 'open_key query_value open_key enum_keys',\n",
       " 'query_value open_key enum_keys open_key',\n",
       " 'query_value open_key query_value load_dll',\n",
       " 'query_value open_file open_key query_value',\n",
       " 'get_host_by_name create_socket create_open_file get_host_by_name',\n",
       " 'kill_process process thread load_image',\n",
       " 'open_key query_value create_mutex open_key',\n",
       " 'query_value create_mutex open_key query_value',\n",
       " 'query_value open_key query_value create_mutex',\n",
       " 'open_key enum_keys open_key enum_keys',\n",
       " 'connect_socket send_socket dump_line recv_socket',\n",
       " 'open_key query_value create_mutex set_windows_hook',\n",
       " 'enum_keys open_key enum_keys open_key',\n",
       " 'impersonate_user open_file get_file_attributes open_file',\n",
       " 'open_file get_file_attributes open_file find_file',\n",
       " 'set_value open_key query_value open_key',\n",
       " 'create_socket create_open_file get_host_by_name create_socket',\n",
       " 'find_file impersonate_user open_file get_file_attributes',\n",
       " 'load_dll open_key query_value create_mutex',\n",
       " 'check_for_debugger load_dll open_key query_value',\n",
       " 'open_file find_file impersonate_user open_file',\n",
       " 'query_value open_key query_value open_file',\n",
       " 'vm_protect vm_write vm_protect vm_write',\n",
       " 'open_key set_value open_key set_value',\n",
       " 'query_value create_mutex set_windows_hook create_window',\n",
       " 'vm_allocate vm_protect vm_write vm_protect',\n",
       " 'load_dll check_for_debugger load_dll open_key',\n",
       " 'query_value load_dll open_key query_value',\n",
       " 'open_file find_file open_key create_process',\n",
       " 'set_windows_hook create_window open_key query_value',\n",
       " 'thread load_image load_dll thread',\n",
       " 'open_key query_value com_create_instance open_key',\n",
       " 'com_create_instance open_key query_value com_create_instance',\n",
       " 'query_value com_create_instance open_key query_value',\n",
       " 'query_value open_key query_value create_directory',\n",
       " 'com_create_instance open_key query_value open_key',\n",
       " 'query_value open_key query_value com_create_instance',\n",
       " 'set_value open_key set_value open_key',\n",
       " 'recv_socket dump_line trimmed_bytes open_url',\n",
       " 'vm_allocate vm_protect vm_write vm_allocate',\n",
       " 'vm_write vm_allocate vm_protect vm_write',\n",
       " 'create_mutex set_windows_hook create_window open_key',\n",
       " 'query_value open_key query_value set_value',\n",
       " 'load_dll open_file open_key query_value',\n",
       " 'dump_line trimmed_bytes open_url recv_socket',\n",
       " 'trimmed_bytes open_url recv_socket dump_line',\n",
       " 'vm_write vm_allocate vm_protect create_thread_remote',\n",
       " 'vm_allocate vm_protect create_thread_remote vm_allocate',\n",
       " 'vm_protect create_thread_remote vm_allocate vm_protect',\n",
       " 'create_directory delete_file create_directory delete_file',\n",
       " 'create_directory delete_file remove_directory create_directory',\n",
       " 'create_directory remove_directory open_file open_key',\n",
       " 'create_process open_file vm_allocate vm_protect',\n",
       " 'create_thread_remote kill_process process thread',\n",
       " 'create_thread_remote vm_allocate vm_protect create_thread_remote',\n",
       " 'delete_file create_directory delete_file remove_directory',\n",
       " 'delete_file remove_directory create_directory delete_file',\n",
       " 'open_file open_key query_value create_directory',\n",
       " 'open_file vm_allocate vm_protect vm_write',\n",
       " 'open_key query_value create_directory remove_directory',\n",
       " 'open_key query_value create_process open_file',\n",
       " 'open_key query_value set_value query_value',\n",
       " 'open_url recv_socket dump_line trimmed_bytes',\n",
       " 'query_value create_directory remove_directory create_directory',\n",
       " 'query_value create_directory remove_directory open_file',\n",
       " 'query_value create_process open_file vm_allocate',\n",
       " 'query_value open_key query_value create_open_file',\n",
       " 'query_value open_key query_value create_process',\n",
       " 'query_value set_value query_value open_key']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_for_df =[]\n",
    "for i in feature[:100]:\n",
    "    features_for_df.append(i[0])\n",
    "features_for_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_dict = {}\n",
    "l = len(train_set) \n",
    "add_dict['id']=[]\n",
    "for i in features_for_df:\n",
    "    add_dict[i] = [0]*l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k, v in file_gram_pair.items():\n",
    "#     add_dict = {}\n",
    "    add_dict['id'].append(k)\n",
    "    \n",
    "    for pair in v :\n",
    "        if pair[0] in features_for_df:\n",
    "            add_dict[pair[0]][count] = pair[1]\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gram_df = pd.DataFrame(add_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       d7aa4c075833e15251aa5832c136fa979e80179da\n",
       "1       a62317c20af9acd81921d0ac790423e4836b88b3e\n",
       "2       0e1574318cb4a8bb36a356bb3f84413e219697583\n",
       "3       c7d03956f0c65913289d0a2e52c74dc5cb9ee87ad\n",
       "4       a3bccc7ef9fb4be9822c0eb8f7c43a7e6d86d0176\n",
       "5       4c62f50fe5ce5358cba99bd05301fb129b668d450\n",
       "6       165db65964196a14eeda3B9b6bbffd8e11fef939d\n",
       "7       391bba3454669d4735c976975685c3e74edc86bf9\n",
       "8       bc5e68c99d4665e73b3b7298d9b76184bcf292472\n",
       "9       9b1c8048fc5bc70b6086ba49e5a350a19a61e0890\n",
       "10      c6fb671992f5bb3821103ccd3f62b2fd68359b63a\n",
       "11      5335235c25c40c5abadcf36c6aa39c99e38729f9c\n",
       "12      6671ee3537f843eacbdf717cded16b4f39895f6a2\n",
       "13      fc216b615c464fd87b19f7bb733549d0ec9168f08\n",
       "14      a683fd7C4e41888e7697b20b6e8096b847ff7edb6\n",
       "15      57fb3150a7ef7fd52e752f79e225a384b2f2aebf4\n",
       "16      4Db4401f865ecf8a46ec239f2ed9e04eed9c6f6a3\n",
       "17      65c274740e82fbed73541670458120d1a14695c7f\n",
       "18      90b6413989fe0cb1b0abea4229206c2252ead3244\n",
       "19      9057189b7919928a7185a42d7fa09f0c7b027beea\n",
       "20      6Ad2551388be9cc3e867ee5e2bf25c1c4a7f0540e\n",
       "21      16aa352334d5bc41dcfef74f79062db3d122408bd\n",
       "22      11fc3a52f1c3bddfcae43b3f8336a53bdcCf68ddb\n",
       "23      1c8386b627b3b2444428f85090b350f00215d5969\n",
       "24      6e2e22bd25Ca1eb0ea07639872de6320b0811724a\n",
       "25      7ef7a13c505f21417f5347752e9c3ce4dcf296e66\n",
       "26      9636bece026eb1eb2a49d5afa17eb1668f04ec0a3\n",
       "27      80d2afdb2213db5b1204c99528182caa90928077e\n",
       "28      2a8d3d005197e3e1ae5fe1b1856cf85654b163ba6\n",
       "29      75f758e6c0b8b4bcb41b8dfeec87fDb6cf8c5b0a9\n",
       "                          ...                    \n",
       "3056    da8c43d814f2e64e36745ec8c5230dcad504d6816\n",
       "3057    40a07625389836375e55a8b9531716244f2e35ed6\n",
       "3058    0b3bb7316a374f2969f5f4016e11b5d4519d87a8b\n",
       "3059    eb206854d8ac0f7503c6c5aefabc91fde1015ffd5\n",
       "3060    d3ebc7955acd6d920262c060d2a56e5f57377144c\n",
       "3061    8a76158588e11b4832d3005a299546ddb2ebeea9b\n",
       "3062    7ca389dabef82df415991d561946b2a8858aa3554\n",
       "3063    2cc743446e34861d36d18b279b5d662a796173E1c\n",
       "3064    763e26975bcc0b1b38679ff7917d75ff22b71cf9d\n",
       "3065    146733a5b21c305e6feC6621c1242fe013147e884\n",
       "3066    d9cEc55c8245fecd7182b7da30fc02c2d751f1438\n",
       "3067    9b653a818ee3507d1cfcbe97c48e13cc2cee8eF3c\n",
       "3068    288a2e406a52da0caac39299d506197725d8df8aa\n",
       "3069    983ccb2cbfdf03994a35a0cdf97870f836b1c4b7a\n",
       "3070    4e1f5f39e9b1fee140fdbf4e4367c2656c789e36b\n",
       "3071    5a1a2effa7b08cbdcaa303e1c881ece98cda5c443\n",
       "3072    020b378a83fa1f9bbab9f302e73Da880b667ff2c9\n",
       "3073    dafb636a6d9dc27626ad1c43496baed17006363ec\n",
       "3074    9f4ac6d907f6dc4b734b1e6deeb9a68b6891b3ce3\n",
       "3075    499baebe496c1130282fe0d0ad67e236500ac875c\n",
       "3076    80f5c00Fdd3b43f562f6c53524795617c215e90fe\n",
       "3077    8ef40d99fc0e82ad3C01406be0f199561a14839f8\n",
       "3078    e3a8d13255ee69d8d4979613dfef32ec37c25ca57\n",
       "3079    9e457e00e4ee6a036C58c20e8ace10d5e7daf026d\n",
       "3080    aaceefe392595b365250ef0bd2dd80bacfcc78e76\n",
       "3081    c2581f19970c8cdfe2287141c73025d08d800dae9\n",
       "3082    d0500e78e31d443f632E2910b85e52b4f03bb2346\n",
       "3083    6108b34df09c7ad406cb49c42483afecc680f6d28\n",
       "3084    ff2f1c2de8cb243aeea30eede3f137b1d3d5E406f\n",
       "3085    d3df7f7bf2e54c9394e8d541fec3880795cb5b7e2\n",
       "Name: id, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['open_key query_value open_key query_value', 63],\n",
       " ['query_value open_key query_value open_key', 56],\n",
       " ['create_file open_file set_file_time set_file_attributes', 3],\n",
       " ['enum_keys open_key query_value open_key', 3],\n",
       " ['open_key enum_keys open_key query_value', 3],\n",
       " ['process thread load_image load_dll', 3],\n",
       " ['load_dll open_key query_value open_file', 2],\n",
       " ['load_dll open_key query_value open_key', 2],\n",
       " ['open_file set_file_time set_file_attributes create_file', 2],\n",
       " ['open_key query_value load_dll create_window', 2],\n",
       " ['open_key query_value open_key enum_keys', 2],\n",
       " ['query_value open_key enum_keys open_key', 2],\n",
       " ['set_file_attributes create_file open_file set_file_time', 2],\n",
       " ['set_file_time set_file_attributes create_file open_file', 2],\n",
       " ['thread load_image load_dll open_file', 2],\n",
       " ['check_for_debugger load_dll open_key load_dll', 1],\n",
       " ['check_for_debugger load_dll open_key query_value', 1],\n",
       " ['com_create_instance get_file_attributes open_file load_dll', 1],\n",
       " ['com_create_instance vm_protect open_key enum_keys', 1],\n",
       " ['com_get_class_object load_dll open_file get_file_attributes', 1],\n",
       " ['create_mutex find_window open_process create_mutex', 1],\n",
       " ['create_mutex find_window open_process find_window', 1],\n",
       " ['create_mutex open_key query_value open_key', 1],\n",
       " ['create_mutex set_windows_hook open_key query_value', 1],\n",
       " ['create_process kill_process thread create_file', 1],\n",
       " ['create_thread load_dll open_key query_value', 1],\n",
       " ['create_thread sleep destroy_window sleep', 1],\n",
       " ['create_window find_window create_window show_window', 1],\n",
       " ['create_window load_dll create_window find_window', 1],\n",
       " ['create_window load_dll create_window show_window', 1],\n",
       " ['create_window load_dll open_file get_file_attributes', 1],\n",
       " ['create_window open_key query_value open_key', 1],\n",
       " ['create_window show_window create_thread sleep', 1],\n",
       " ['create_window show_window open_key query_value', 1],\n",
       " ['destroy_window create_process kill_process thread', 1],\n",
       " ['destroy_window sleep create_window load_dll', 1],\n",
       " ['enum_keys open_key enum_keys open_key', 1],\n",
       " ['enum_values open_key query_value open_key', 1],\n",
       " ['find_file com_get_class_object load_dll open_file', 1],\n",
       " ['find_file load_dll open_key query_value', 1],\n",
       " ['find_file open_key load_dll open_key', 1],\n",
       " ['find_window create_window show_window open_key', 1],\n",
       " ['find_window get_file_attributes create_window load_dll', 1],\n",
       " ['find_window open_process create_mutex find_window', 1],\n",
       " ['find_window open_process find_window get_file_attributes', 1],\n",
       " ['get_file_attributes create_window load_dll create_window', 1],\n",
       " ['get_file_attributes find_file load_dll open_key', 1],\n",
       " ['get_file_attributes load_dll get_file_attributes open_file', 1],\n",
       " ['get_file_attributes open_file load_dll open_file', 1],\n",
       " ['get_file_attributes open_file load_dll open_key', 1],\n",
       " ['kill_process thread create_file open_file', 1],\n",
       " ['load_dll check_for_debugger load_dll open_key', 1],\n",
       " ['load_dll com_create_instance get_file_attributes open_file', 1],\n",
       " ['load_dll create_window find_window create_window', 1],\n",
       " ['load_dll create_window load_dll create_window', 1],\n",
       " ['load_dll create_window open_key query_value', 1],\n",
       " ['load_dll create_window show_window create_thread', 1],\n",
       " ['load_dll get_file_attributes open_file load_dll', 1],\n",
       " ['load_dll get_file_attributes open_file open_process', 1],\n",
       " ['load_dll open_file check_for_debugger load_dll', 1],\n",
       " ['load_dll open_file get_file_attributes find_file', 1],\n",
       " ['load_dll open_file get_file_attributes load_dll', 1],\n",
       " ['load_dll open_file load_dll check_for_debugger', 1],\n",
       " ['load_dll open_file open_key query_value', 1],\n",
       " ['load_dll open_key destroy_window create_process', 1],\n",
       " ['load_dll open_key load_dll get_file_attributes', 1],\n",
       " ['load_dll open_key query_value create_mutex', 1],\n",
       " ['load_dll process thread load_image', 1],\n",
       " ['load_dll thread sleep process', 1],\n",
       " ['load_image load_dll open_file check_for_debugger', 1],\n",
       " ['load_image load_dll open_file load_dll', 1],\n",
       " ['load_image load_dll process thread', 1],\n",
       " ['open_file check_for_debugger load_dll open_key', 1],\n",
       " ['open_file com_create_instance vm_protect open_key', 1],\n",
       " ['open_file find_file open_key load_dll', 1],\n",
       " ['open_file get_file_attributes find_file load_dll', 1],\n",
       " ['open_file get_file_attributes load_dll get_file_attributes', 1],\n",
       " ['open_file load_dll check_for_debugger load_dll', 1],\n",
       " ['open_file load_dll com_create_instance get_file_attributes', 1],\n",
       " ['open_file load_dll open_file open_key', 1],\n",
       " ['open_file load_dll open_key query_value', 1],\n",
       " ['open_file open_key query_value open_file', 1],\n",
       " ['open_file open_key query_value open_key', 1],\n",
       " ['open_file set_file_time set_file_attributes load_dll', 1],\n",
       " ['open_key create_mutex find_window open_process', 1],\n",
       " ['open_key destroy_window create_process kill_process', 1],\n",
       " ['open_key enum_keys open_key enum_keys', 1],\n",
       " ['open_key load_dll get_file_attributes open_file', 1],\n",
       " ['open_key load_dll open_key destroy_window', 1],\n",
       " ['open_key query_value create_mutex open_key', 1],\n",
       " ['open_key query_value create_mutex set_windows_hook', 1],\n",
       " ['open_key query_value create_thread load_dll', 1],\n",
       " ['open_key query_value enum_values open_key', 1],\n",
       " ['open_key query_value find_file com_get_class_object', 1],\n",
       " ['open_key query_value open_file com_create_instance', 1],\n",
       " ['open_key query_value open_file find_file', 1],\n",
       " ['open_key query_value open_file load_dll', 1],\n",
       " ['open_key query_value open_file open_key', 1],\n",
       " ['open_key query_value open_key create_mutex', 1],\n",
       " ['open_key query_value vm_protect load_dll', 1],\n",
       " ['open_process create_mutex find_window open_process', 1],\n",
       " ['open_process find_window get_file_attributes create_window', 1],\n",
       " ['query_value create_mutex open_key query_value', 1],\n",
       " ['query_value create_mutex set_windows_hook open_key', 1],\n",
       " ['query_value create_thread load_dll open_key', 1],\n",
       " ['query_value enum_values open_key query_value', 1],\n",
       " ['query_value find_file com_get_class_object load_dll', 1],\n",
       " ['query_value load_dll create_window load_dll', 1],\n",
       " ['query_value load_dll create_window open_key', 1],\n",
       " ['query_value open_file com_create_instance vm_protect', 1],\n",
       " ['query_value open_file find_file open_key', 1],\n",
       " ['query_value open_file load_dll com_create_instance', 1],\n",
       " ['query_value open_file open_key query_value', 1],\n",
       " ['query_value open_key create_mutex find_window', 1],\n",
       " ['query_value open_key query_value create_mutex', 1],\n",
       " ['query_value open_key query_value create_thread', 1],\n",
       " ['query_value open_key query_value enum_values', 1],\n",
       " ['query_value open_key query_value find_file', 1],\n",
       " ['query_value open_key query_value load_dll', 1],\n",
       " ['query_value open_key query_value open_file', 1],\n",
       " ['query_value open_key query_value vm_protect', 1],\n",
       " ['query_value vm_protect load_dll open_key', 1],\n",
       " ['set_file_attributes load_dll thread sleep', 1],\n",
       " ['set_file_time set_file_attributes load_dll thread', 1],\n",
       " ['set_windows_hook open_key query_value load_dll', 1],\n",
       " ['show_window create_thread sleep destroy_window', 1],\n",
       " ['show_window open_key query_value open_key', 1],\n",
       " ['sleep create_window load_dll open_file', 1],\n",
       " ['sleep destroy_window sleep create_window', 1],\n",
       " ['sleep process thread load_image', 1],\n",
       " ['thread create_file open_file set_file_time', 1],\n",
       " ['thread load_image load_dll process', 1],\n",
       " ['thread sleep process thread', 1],\n",
       " ['vm_protect load_dll open_key query_value', 1],\n",
       " ['vm_protect open_key enum_keys open_key', 1]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_gram_pair[file_gram_pair.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gram_train_df = pd.merge(train_set, gram_df, on = 'id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gram_train_df = gram_train_df.drop(['class'], axis=1)\n",
    "gram_train_df = gram_train_df.drop(['id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clfrf, Xtrain, ytrain, Xtest, ytest = do_classify(RandomForestClassifier(random_state=123),\n",
    "                                                   {\"max_depth\": [50],\n",
    "                                                    \"n_estimators\":[20]}, \n",
    "                                                   gram_train_df,t_train,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accept_socket</th>\n",
       "      <th>add_netjob</th>\n",
       "      <th>all_section</th>\n",
       "      <th>bind_socket</th>\n",
       "      <th>change_service_config</th>\n",
       "      <th>check_for_debugger</th>\n",
       "      <th>com_create_instance</th>\n",
       "      <th>com_createole_object</th>\n",
       "      <th>com_get_class_object</th>\n",
       "      <th>connect</th>\n",
       "      <th>...</th>\n",
       "      <th>thread</th>\n",
       "      <th>trimmed_bytes</th>\n",
       "      <th>unload_driver</th>\n",
       "      <th>vm_allocate</th>\n",
       "      <th>vm_mapviewofsection</th>\n",
       "      <th>vm_protect</th>\n",
       "      <th>vm_read</th>\n",
       "      <th>vm_write</th>\n",
       "      <th>write_value</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0015c8c9ff02fea9d0f45692b9eebfb4abff4e42f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>255</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>001f298a534ae4b0db7f2707169250aa215c3b5f2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>001f5fdaaa8bbe20303527198d09a30bb7ca3eb50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>002ca2c41b649f85c05ae30013436781a932fecc6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>003e109543b4ea22d2bcc1ec309bf2fd34e9a1a1d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 107 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accept_socket  add_netjob  all_section  bind_socket  change_service_config  \\\n",
       "0              0           0            5            0                      0   \n",
       "1              0           0            6            2                      0   \n",
       "2              0           0            2            0                      0   \n",
       "3              0           0            6            5                      0   \n",
       "4              0           0            1            0                      0   \n",
       "\n",
       "   check_for_debugger  com_create_instance  com_createole_object  \\\n",
       "0                   2                    2                     0   \n",
       "1                   2                    1                     0   \n",
       "2                   0                    0                     0   \n",
       "3                   2                    1                     0   \n",
       "4                   1                    0                     0   \n",
       "\n",
       "   com_get_class_object  connect                    ...                      \\\n",
       "0                     1        0                    ...                       \n",
       "1                     0        0                    ...                       \n",
       "2                     0        0                    ...                       \n",
       "3                     1        1                    ...                       \n",
       "4                     0        0                    ...                       \n",
       "\n",
       "   thread  trimmed_bytes  unload_driver  vm_allocate  vm_mapviewofsection  \\\n",
       "0       5              0              0            0                    0   \n",
       "1       6              1              0            8                    0   \n",
       "2       2              0              0            0                    0   \n",
       "3       6             13              0            0                    0   \n",
       "4       1              0              0            0                    0   \n",
       "\n",
       "   vm_protect  vm_read  vm_write  write_value  \\\n",
       "0          36        0         0            0   \n",
       "1         255        0         5            0   \n",
       "2           0        0         0            0   \n",
       "3          72        0         0            0   \n",
       "4           0        0         0            0   \n",
       "\n",
       "                                          id  \n",
       "0  0015c8c9ff02fea9d0f45692b9eebfb4abff4e42f  \n",
       "1  001f298a534ae4b0db7f2707169250aa215c3b5f2  \n",
       "2  001f5fdaaa8bbe20303527198d09a30bb7ca3eb50  \n",
       "3  002ca2c41b649f85c05ae30013436781a932fecc6  \n",
       "4  003e109543b4ea22d2bcc1ec309bf2fd34e9a1a1d  \n",
       "\n",
       "[5 rows x 107 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whole_test_file = dict()\n",
    "\n",
    "for datafile in os.listdir('test'):\n",
    "    if datafile == '.DS_Store':\n",
    "        continue\n",
    "        \n",
    "    file1_tag_flow = []\n",
    "    file1 = open('test/'+datafile, 'r')\n",
    "#     file1.readline()\n",
    "    for line in file1:\n",
    "        tag = line.split(' ')[0][1:]\n",
    "        if tag in list(call_set):\n",
    "            file1_tag_flow.append(tag)\n",
    "    \n",
    "    file1_tag_flow_unique = [file1_tag_flow[0]]\n",
    "    for i in range(1, len(file1_tag_flow)):\n",
    "        if file1_tag_flow[i] == file1_tag_flow_unique[-1]:\n",
    "            continue\n",
    "        else :\n",
    "            file1_tag_flow_unique.append(file1_tag_flow[i])\n",
    "        \n",
    "    whole_test_file[datafile.split('.')[0]] = file1_tag_flow_unique\n",
    "# print file1_tag_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import itemfreq\n",
    "\n",
    "file_gram_pair_test = dict()\n",
    "\n",
    "for k in whole_test_file.keys():\n",
    "    file1_tag_flow_unique = whole_test_file[k]\n",
    "#     N = 4 # bi-grams\n",
    "    grams=[]\n",
    "#     for n in range(2,5):\n",
    "    n = 4\n",
    "    grams += [file1_tag_flow_unique[i:i+n] for i in xrange(len(file1_tag_flow_unique)-n)]\n",
    "    #print len(grams)\n",
    "    # ?itemfreq\n",
    "\n",
    "    single_key_grams = []\n",
    "    for i in grams:\n",
    "        single_key_grams.append(' '.join(i))\n",
    "        \n",
    "    grams = []\n",
    "    for i in list(itemfreq(single_key_grams)):\n",
    "        grams.append([i[0], int(i[1])])\n",
    "    grams.sort(key = lambda x: x[1], reverse = True) \n",
    "    file_gram_pair_test[k] = grams\n",
    "# print itemfreq(grams)\n",
    "\n",
    "# for i in file1_tag_flow_unique:\n",
    "#     for j in file1_tag_flow_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['open_key query_value open_key query_value', 63],\n",
       " ['query_value open_key query_value open_key', 56],\n",
       " ['enum_keys open_key query_value open_key', 3],\n",
       " ['open_key enum_keys open_key query_value', 3],\n",
       " ['process thread load_image load_dll', 3],\n",
       " ['load_dll open_key query_value open_file', 2],\n",
       " ['load_dll open_key query_value open_key', 2],\n",
       " ['open_key query_value load_dll create_window', 2],\n",
       " ['open_key query_value open_key enum_keys', 2],\n",
       " ['query_value open_key enum_keys open_key', 2],\n",
       " ['thread load_image load_dll open_file', 2],\n",
       " ['check_for_debugger load_dll open_key load_dll', 1],\n",
       " ['check_for_debugger load_dll open_key query_value', 1],\n",
       " ['com_create_instance get_file_attributes open_file load_dll', 1],\n",
       " ['com_create_instance vm_protect open_key enum_keys', 1],\n",
       " ['com_get_class_object load_dll open_file get_file_attributes', 1],\n",
       " ['create_file open_file set_file_time set_file_attributes', 1],\n",
       " ['create_mutex find_window open_process create_mutex', 1],\n",
       " ['create_mutex get_file_attributes create_window load_dll', 1],\n",
       " ['create_mutex open_key query_value open_key', 1],\n",
       " ['create_mutex set_windows_hook open_key query_value', 1],\n",
       " ['create_process kill_process thread create_file', 1],\n",
       " ['create_thread load_dll open_key query_value', 1],\n",
       " ['create_thread sleep destroy_window sleep', 1],\n",
       " ['create_window find_window create_window show_window', 1],\n",
       " ['create_window load_dll create_window find_window', 1],\n",
       " ['create_window load_dll create_window show_window', 1],\n",
       " ['create_window load_dll open_file get_file_attributes', 1],\n",
       " ['create_window open_key query_value open_key', 1],\n",
       " ['create_window show_window create_thread sleep', 1],\n",
       " ['create_window show_window open_key query_value', 1],\n",
       " ['destroy_window create_process kill_process thread', 1],\n",
       " ['destroy_window sleep create_window load_dll', 1],\n",
       " ['enum_keys open_key enum_keys open_key', 1],\n",
       " ['enum_values open_key query_value open_key', 1],\n",
       " ['find_file com_get_class_object load_dll open_file', 1],\n",
       " ['find_file load_dll open_key query_value', 1],\n",
       " ['find_file open_key load_dll open_key', 1],\n",
       " ['find_window create_window show_window open_key', 1],\n",
       " ['find_window open_process create_mutex get_file_attributes', 1],\n",
       " ['get_file_attributes create_window load_dll create_window', 1],\n",
       " ['get_file_attributes find_file load_dll open_key', 1],\n",
       " ['get_file_attributes load_dll get_file_attributes open_file', 1],\n",
       " ['get_file_attributes open_file load_dll open_file', 1],\n",
       " ['get_file_attributes open_file load_dll open_key', 1],\n",
       " ['kill_process thread create_file open_file', 1],\n",
       " ['load_dll check_for_debugger load_dll open_key', 1],\n",
       " ['load_dll com_create_instance get_file_attributes open_file', 1],\n",
       " ['load_dll create_window find_window create_window', 1],\n",
       " ['load_dll create_window load_dll create_window', 1],\n",
       " ['load_dll create_window open_key query_value', 1],\n",
       " ['load_dll create_window show_window create_thread', 1],\n",
       " ['load_dll get_file_attributes open_file load_dll', 1],\n",
       " ['load_dll get_file_attributes open_file open_process', 1],\n",
       " ['load_dll open_file check_for_debugger load_dll', 1],\n",
       " ['load_dll open_file get_file_attributes find_file', 1],\n",
       " ['load_dll open_file get_file_attributes load_dll', 1],\n",
       " ['load_dll open_file load_dll check_for_debugger', 1],\n",
       " ['load_dll open_file open_key query_value', 1],\n",
       " ['load_dll open_key destroy_window create_process', 1],\n",
       " ['load_dll open_key load_dll get_file_attributes', 1],\n",
       " ['load_dll open_key query_value create_mutex', 1],\n",
       " ['load_dll process thread load_image', 1],\n",
       " ['load_dll thread sleep process', 1],\n",
       " ['load_image load_dll open_file check_for_debugger', 1],\n",
       " ['load_image load_dll open_file load_dll', 1],\n",
       " ['load_image load_dll process thread', 1],\n",
       " ['open_file check_for_debugger load_dll open_key', 1],\n",
       " ['open_file com_create_instance vm_protect open_key', 1],\n",
       " ['open_file find_file open_key load_dll', 1],\n",
       " ['open_file get_file_attributes find_file load_dll', 1],\n",
       " ['open_file get_file_attributes load_dll get_file_attributes', 1],\n",
       " ['open_file load_dll check_for_debugger load_dll', 1],\n",
       " ['open_file load_dll com_create_instance get_file_attributes', 1],\n",
       " ['open_file load_dll open_file open_key', 1],\n",
       " ['open_file load_dll open_key query_value', 1],\n",
       " ['open_file open_key query_value open_file', 1],\n",
       " ['open_file open_key query_value open_key', 1],\n",
       " ['open_file set_file_time set_file_attributes load_dll', 1],\n",
       " ['open_key create_mutex find_window open_process', 1],\n",
       " ['open_key destroy_window create_process kill_process', 1],\n",
       " ['open_key enum_keys open_key enum_keys', 1],\n",
       " ['open_key load_dll get_file_attributes open_file', 1],\n",
       " ['open_key load_dll open_key destroy_window', 1],\n",
       " ['open_key query_value create_mutex open_key', 1],\n",
       " ['open_key query_value create_mutex set_windows_hook', 1],\n",
       " ['open_key query_value create_thread load_dll', 1],\n",
       " ['open_key query_value enum_values open_key', 1],\n",
       " ['open_key query_value find_file com_get_class_object', 1],\n",
       " ['open_key query_value open_file com_create_instance', 1],\n",
       " ['open_key query_value open_file find_file', 1],\n",
       " ['open_key query_value open_file load_dll', 1],\n",
       " ['open_key query_value open_file open_key', 1],\n",
       " ['open_key query_value open_key create_mutex', 1],\n",
       " ['open_key query_value vm_protect load_dll', 1],\n",
       " ['open_process create_mutex get_file_attributes create_window', 1],\n",
       " ['query_value create_mutex open_key query_value', 1],\n",
       " ['query_value create_mutex set_windows_hook open_key', 1],\n",
       " ['query_value create_thread load_dll open_key', 1],\n",
       " ['query_value enum_values open_key query_value', 1],\n",
       " ['query_value find_file com_get_class_object load_dll', 1],\n",
       " ['query_value load_dll create_window load_dll', 1],\n",
       " ['query_value load_dll create_window open_key', 1],\n",
       " ['query_value open_file com_create_instance vm_protect', 1],\n",
       " ['query_value open_file find_file open_key', 1],\n",
       " ['query_value open_file load_dll com_create_instance', 1],\n",
       " ['query_value open_file open_key query_value', 1],\n",
       " ['query_value open_key create_mutex find_window', 1],\n",
       " ['query_value open_key query_value create_mutex', 1],\n",
       " ['query_value open_key query_value create_thread', 1],\n",
       " ['query_value open_key query_value enum_values', 1],\n",
       " ['query_value open_key query_value find_file', 1],\n",
       " ['query_value open_key query_value load_dll', 1],\n",
       " ['query_value open_key query_value open_file', 1],\n",
       " ['query_value open_key query_value vm_protect', 1],\n",
       " ['query_value vm_protect load_dll open_key', 1],\n",
       " ['set_file_attributes load_dll thread sleep', 1],\n",
       " ['set_file_time set_file_attributes load_dll thread', 1],\n",
       " ['set_windows_hook open_key query_value load_dll', 1],\n",
       " ['show_window create_thread sleep destroy_window', 1],\n",
       " ['show_window open_key query_value open_key', 1],\n",
       " ['sleep create_window load_dll open_file', 1],\n",
       " ['sleep destroy_window sleep create_window', 1],\n",
       " ['sleep process thread load_image', 1],\n",
       " ['thread create_file open_file set_file_time', 1],\n",
       " ['thread load_image load_dll process', 1],\n",
       " ['thread sleep process thread', 1],\n",
       " ['vm_protect load_dll open_key query_value', 1],\n",
       " ['vm_protect open_key enum_keys open_key', 1]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_gram_pair_test[file_gram_pair_test.keys()[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "add_dict_test = {}\n",
    "l_test = len(test_set) \n",
    "add_dict_test['id']=[]\n",
    "for i in features_for_df:\n",
    "    add_dict_test[i] = [0]*l_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for k, v in file_gram_pair_test.items():\n",
    "#     add_dict = {}\n",
    "    add_dict_test['id'].append(k)\n",
    "    \n",
    "    for pair in v :\n",
    "        if pair[0] in features_for_df:\n",
    "            add_dict_test[pair[0]][count] = pair[1]\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gram_df_test = pd.DataFrame(add_dict_test)\n",
    "gram_test_df = pd.merge(test_set, gram_df_test, on = 'id')\n",
    "gram_test_df = gram_test_df.drop(['id'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accept_socket</th>\n",
       "      <th>add_netjob</th>\n",
       "      <th>all_section</th>\n",
       "      <th>bind_socket</th>\n",
       "      <th>change_service_config</th>\n",
       "      <th>check_for_debugger</th>\n",
       "      <th>com_create_instance</th>\n",
       "      <th>com_createole_object</th>\n",
       "      <th>com_get_class_object</th>\n",
       "      <th>connect</th>\n",
       "      <th>...</th>\n",
       "      <th>trimmed_bytes recv_socket dump_line trimmed_bytes</th>\n",
       "      <th>trimmed_bytes send_socket dump_line trimmed_bytes</th>\n",
       "      <th>vm_allocate vm_protect create_thread_remote vm_allocate</th>\n",
       "      <th>vm_allocate vm_protect vm_write vm_allocate</th>\n",
       "      <th>vm_allocate vm_protect vm_write vm_protect</th>\n",
       "      <th>vm_protect create_thread_remote vm_allocate vm_protect</th>\n",
       "      <th>vm_protect vm_write vm_allocate vm_protect</th>\n",
       "      <th>vm_protect vm_write vm_protect vm_write</th>\n",
       "      <th>vm_write vm_allocate vm_protect create_thread_remote</th>\n",
       "      <th>vm_write vm_allocate vm_protect vm_write</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 206 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   accept_socket  add_netjob  all_section  bind_socket  change_service_config  \\\n",
       "0              0           0            5            0                      0   \n",
       "1              0           0            6            2                      0   \n",
       "2              0           0            2            0                      0   \n",
       "3              0           0            6            5                      0   \n",
       "4              0           0            1            0                      0   \n",
       "\n",
       "   check_for_debugger  com_create_instance  com_createole_object  \\\n",
       "0                   2                    2                     0   \n",
       "1                   2                    1                     0   \n",
       "2                   0                    0                     0   \n",
       "3                   2                    1                     0   \n",
       "4                   1                    0                     0   \n",
       "\n",
       "   com_get_class_object  connect                    ...                     \\\n",
       "0                     1        0                    ...                      \n",
       "1                     0        0                    ...                      \n",
       "2                     0        0                    ...                      \n",
       "3                     1        1                    ...                      \n",
       "4                     0        0                    ...                      \n",
       "\n",
       "   trimmed_bytes recv_socket dump_line trimmed_bytes  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  9   \n",
       "4                                                  0   \n",
       "\n",
       "   trimmed_bytes send_socket dump_line trimmed_bytes  \\\n",
       "0                                                  0   \n",
       "1                                                  0   \n",
       "2                                                  0   \n",
       "3                                                  0   \n",
       "4                                                  0   \n",
       "\n",
       "   vm_allocate vm_protect create_thread_remote vm_allocate  \\\n",
       "0                                                  0         \n",
       "1                                                  1         \n",
       "2                                                  0         \n",
       "3                                                  0         \n",
       "4                                                  0         \n",
       "\n",
       "   vm_allocate vm_protect vm_write vm_allocate  \\\n",
       "0                                            0   \n",
       "1                                            3   \n",
       "2                                            0   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   vm_allocate vm_protect vm_write vm_protect  \\\n",
       "0                                           0   \n",
       "1                                           1   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   vm_protect create_thread_remote vm_allocate vm_protect  \\\n",
       "0                                                  0        \n",
       "1                                                  1        \n",
       "2                                                  0        \n",
       "3                                                  0        \n",
       "4                                                  0        \n",
       "\n",
       "   vm_protect vm_write vm_allocate vm_protect  \\\n",
       "0                                           0   \n",
       "1                                           4   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   vm_protect vm_write vm_protect vm_write  \\\n",
       "0                                        0   \n",
       "1                                        1   \n",
       "2                                        0   \n",
       "3                                        0   \n",
       "4                                        0   \n",
       "\n",
       "   vm_write vm_allocate vm_protect create_thread_remote  \\\n",
       "0                                                  0      \n",
       "1                                                  1      \n",
       "2                                                  0      \n",
       "3                                                  0      \n",
       "4                                                  0      \n",
       "\n",
       "   vm_write vm_allocate vm_protect vm_write  \n",
       "0                                         0  \n",
       "1                                         3  \n",
       "2                                         0  \n",
       "3                                         0  \n",
       "4                                         0  \n",
       "\n",
       "[5 rows x 206 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_test=clfrf.predict(gram_test_df)\n",
    "write_predictions(t_test,test_ids,\"new_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3724, 206)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3086, 207)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gram_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'learning_rate': 0.1, 'random_state': 1} 0.879166666667 [mean: 0.87917, std: 0.01674, params: {'learning_rate': 0.1, 'random_state': 1}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.98\n",
      "Accuracy on test data:     0.90\n",
      "[[ 16   0   0   0   0   0   0   1  10   3   0   1   3   1   0]\n",
      " [  0   8   0   0   0   0   0   0   2   1   0   0   4   1   0]\n",
      " [  0   0  10   0   0   1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  11   0   1   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   8   0   0   0   4   0   0   0   0   1   0]\n",
      " [  0   1   0   0   0   5   0   0   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  11   0   1   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   8   2   0   0   0   0   0   0]\n",
      " [  6   1   1   0   2   0   0   0 484   0   2   1   3   3   1]\n",
      " [  0   0   0   0   0   0   0   0   2   2   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   1   0   0   8   0   0   0]\n",
      " [  3   0   0   0   0   0   0   0   2   1   0   0 101   0   0]\n",
      " [  1   0   0   0   0   0   0   0  11   0   0   0   1   6   0]\n",
      " [  0   3   0   0   0   0   0   0   3   0   0   0   0   0  10]]\n",
      "########################################################\n",
      "CPU times: user 3min 56s, sys: 12.4 s, total: 4min 9s\n",
      "Wall time: 4min 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clfxbf, Xtrain, ytrain, Xtest, ytest = do_classify(GradientBoostingClassifier(),\n",
    "                                                   {\"learning_rate\": [0.1],\n",
    "                                                    \"random_state\":[1]}, \n",
    "                                                   gram_train_df,t_train,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_test=clfxbf.predict(gram_test_df)\n",
    "write_predictions(t_test,test_ids,\"new_features_xbf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using reuse split\n",
      "BEST {'C': 1.0, 'solver': 'newton-cg'} 0.772685185185 [mean: 0.75000, std: 0.01523, params: {'C': 0.01, 'solver': 'newton-cg'}, mean: 0.76991, std: 0.00790, params: {'C': 0.1, 'solver': 'newton-cg'}, mean: 0.77269, std: 0.00859, params: {'C': 1.0, 'solver': 'newton-cg'}, mean: 0.76944, std: 0.00878, params: {'C': 10.0, 'solver': 'newton-cg'}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.84\n",
      "Accuracy on test data:     0.77\n",
      "[[ 14   0   0   2   5   3   0   1   2   1   0   0   2   5   0]\n",
      " [  0   8   0   0   0   0   0   0   0   3   0   1   4   0   0]\n",
      " [  0   0   5   3   1   2   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   2   9   0   1   0   0   1   0   0   0   0   0   0]\n",
      " [  0   0   1   0   9   0   0   0   0   1   0   0   2   0   0]\n",
      " [  0   1   0   0   0   5   0   0   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  11   0   1   0   0   0   0   0   0]\n",
      " [  1   0   0   1   0   0   0   8   0   0   0   0   0   0   0]\n",
      " [  5   1   4   4  11   1   2   4 371  25   2   3  25  46   0]\n",
      " [  1   0   0   0   0   0   0   0   1   3   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 145   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   1   8   0   1   0]\n",
      " [  2   0   0   0   0   2   0   0   1   2   0   0  99   1   0]\n",
      " [  1   0   0   0   0   0   0   1   1   1   0   0   0  15   0]\n",
      " [  2   1   1   1   0   0   0   0   0   1   0   2   1   3   4]]\n",
      "########################################################\n",
      "CPU times: user 7min 8s, sys: 29.2 s, total: 7min 37s\n",
      "Wall time: 5min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "clflr, Xtrain, ytrain, Xtest, ytest = do_classify(LogisticRegression(penalty=\"l2\",random_state=12,\\\n",
    "                                                                     multi_class=\"multinomial\",class_weight='balanced'), \\\n",
    "                                                   {\"C\": [0.01, 0.1, 1.0, 10.0],\"solver\":[\"newton-cg\"]},\n",
    "                                                   gram_train_df,t_train,reuse_split=reuse_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using reuse split\n",
      "BEST {'C': 1.0, 'solver': 'newton-cg'} 0.856944444444 [mean: 0.85694, std: 0.01795, params: {'C': 1.0, 'solver': 'newton-cg'}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.91\n",
      "Accuracy on test data:     0.84\n",
      "[[ 14   0   0   0   0   1   0   2  15   0   1   0   2   0   0]\n",
      " [  0   8   0   0   0   0   0   0   1   2   0   0   5   0   0]\n",
      " [  0   0   4   3   0   1   0   1   2   0   0   0   0   0   0]\n",
      " [  0   0   1   6   0   4   0   0   2   0   0   0   0   0   0]\n",
      " [  0   0   0   0   6   0   1   0   3   0   0   0   3   0   0]\n",
      " [  0   0   0   0   0   5   0   0   2   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0  10   0   2   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   4   4   0   0   0   0   0   0]\n",
      " [  6   0   2   0   0   1   3   1 466   1   6   1  17   0   0]\n",
      " [  1   1   0   0   0   0   0   0   2   0   1   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   1   0   0   8   0   0   0]\n",
      " [  2   0   0   0   1   1   0   0   4   0   0   0  99   0   0]\n",
      " [  1   0   0   0   0   0   0   0  16   0   0   0   1   1   0]\n",
      " [  3   1   0   0   0   0   0   0   4   0   2   2   0   0   4]]\n",
      "########################################################\n"
     ]
    }
   ],
   "source": [
    "clflr2, Xtrain, ytrain, Xtest, ytest = do_classify(LogisticRegression(penalty=\"l2\",random_state=12,\\\n",
    "                                                                     multi_class=\"multinomial\"), \\\n",
    "                                                   {\"C\": [1.0],\"solver\":[\"newton-cg\"]},\n",
    "                                                   gram_train_df,t_train,reuse_split=reuse_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#t_test=clflr.predict(gram_test_df)\n",
    "write_predictions(t_test,test_ids,\"ggm2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from GaussianGenerativeModel import GaussianGenerativeModel\n",
    "\n",
    "nb1 = GaussianGenerativeModel(isSharedCovariance=False)\n",
    "nb1.fit(gram_train_df.values,t_train)\n",
    "call_list=list(call_set)\n",
    "t_test=nb1.predict(gram_test_df.values,call_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convertT(C,cls):\n",
    "    num_cls=len(cls)\n",
    "    nobs=len(C)\n",
    "    classes=np.zeros((nobs,num_cls))\n",
    "    for j in np.arange(nobs):\n",
    "        for i in np.arange(num_cls):\n",
    "            if C[j]==cls[i]:\n",
    "                classes[j,i]=1\n",
    "    return classes\n",
    "\n",
    "clslist=np.arange(15)\n",
    "classes = convertT(t_train, clslist)\n",
    "freq=np.sum(classes,axis=0)/np.sum(classes)\n",
    "clswgt = dict(zip(clslist,freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.036941023979261182,\n",
       " 1: 0.016202203499675955,\n",
       " 2: 0.011989630589760207,\n",
       " 3: 0.010369410239792612,\n",
       " 4: 0.013285806869734284,\n",
       " 5: 0.012637718729747246,\n",
       " 6: 0.017174335709656513,\n",
       " 7: 0.013285806869734284,\n",
       " 8: 0.52138690861957226,\n",
       " 9: 0.0068049254698639011,\n",
       " 10: 0.17563188593648738,\n",
       " 11: 0.010369410239792612,\n",
       " 12: 0.12184057031756319,\n",
       " 13: 0.019118600129617629,\n",
       " 14: 0.012961762799740765}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clswgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n",
      "/Users/Jing/anaconda/lib/python2.7/site-packages/sklearn/utils/optimize.py:200: UserWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\"newton-cg failed to converge. Increase the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'C': 0.1, 'solver': 'newton-cg'} 0.770833333333 [mean: 0.75509, std: 0.01378, params: {'C': 0.01, 'solver': 'newton-cg'}, mean: 0.77083, std: 0.04428, params: {'C': 0.1, 'solver': 'newton-cg'}, mean: 0.76759, std: 0.04508, params: {'C': 1.0, 'solver': 'newton-cg'}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.77\n",
      "Accuracy on test data:     0.75\n",
      "[[  4   0   1   0   0   1   0   0  28   0   0   0   0   1   0]\n",
      " [  0   1   0   0   0   0   0   0   8   0   2   0   5   0   0]\n",
      " [  1   0   3   1   0   0   0   0   6   0   0   0   0   0   0]\n",
      " [  0   0   1   7   0   1   0   0   2   0   1   0   1   0   0]\n",
      " [  0   1   0   0   0   0   0   0  12   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0   0   5   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   9   0   2   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   3   7   0   0   0   0   0   0]\n",
      " [  5   1   1   1   0   1   1   0 484   0   6   1   3   0   0]\n",
      " [  0   0   0   0   0   0   0   0   5   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   1   0 145   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   9   0   1   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0  76   0   0   0  30   0   0]\n",
      " [  1   0   0   0   0   0   0   0  17   0   1   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   4   0   4   0   2   0   5]]\n",
      "########################################################\n",
      "CPU times: user 11min 24s, sys: 23.8 s, total: 11min 48s\n",
      "Wall time: 5min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "clflr, Xtrain, ytrain, Xtest, ytest = do_classify(LogisticRegression(penalty=\"l2\",random_state=12,\\\n",
    "                                                                     multi_class=\"multinomial\",class_weight=clswgt), \\\n",
    "                                                   {\"C\": [0.01, 0.1, 1.0],\"solver\":[\"newton-cg\"]},\n",
    "                                                   gram_train_df,t_train,mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using mask\n",
      "BEST {'learning_rate': 0.05, 'max_depth': 5} 0.880092592593 [mean: 0.87963, std: 0.01939, params: {'learning_rate': 0.05, 'max_depth': 3}, mean: 0.88009, std: 0.01562, params: {'learning_rate': 0.05, 'max_depth': 5}, mean: 0.87269, std: 0.01289, params: {'learning_rate': 0.05, 'max_depth': 10}, mean: 0.87917, std: 0.01914, params: {'learning_rate': 0.1, 'max_depth': 3}, mean: 0.87731, std: 0.01143, params: {'learning_rate': 0.1, 'max_depth': 5}, mean: 0.87870, std: 0.01247, params: {'learning_rate': 0.1, 'max_depth': 10}, mean: 0.87315, std: 0.01231, params: {'learning_rate': 0.2, 'max_depth': 3}, mean: 0.87361, std: 0.01357, params: {'learning_rate': 0.2, 'max_depth': 5}, mean: 0.87593, std: 0.01306, params: {'learning_rate': 0.2, 'max_depth': 10}]\n",
      "############# based on standard predict ################\n",
      "Accuracy on training data: 0.99\n",
      "Accuracy on test data:     0.90\n",
      "[[ 16   0   0   0   0   0   0   1  11   3   0   1   2   1   0]\n",
      " [  0   8   0   1   0   0   0   0   1   1   0   0   4   1   0]\n",
      " [  0   0  10   0   0   1   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0  11   0   1   0   0   1   0   0   0   0   0   0]\n",
      " [  1   0   0   0   6   0   0   0   5   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   5   0   0   3   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  11   0   1   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   8   1   0   0   0   0   0   0]\n",
      " [  6   0   2   0   2   0   0   0 482   0   2   1   5   3   1]\n",
      " [  0   0   0   0   0   0   0   0   2   2   0   0   1   1   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0 146   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   1   0   0   8   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   5   1   0   0 101   0   0]\n",
      " [  1   0   0   0   0   0   0   0  13   0   0   0   0   5   0]\n",
      " [  1   0   0   0   0   0   0   0   3   0   0   0   0   0  12]]\n",
      "########################################################\n",
      "CPU times: user 15min 33s, sys: 5.66 s, total: 15min 39s\n",
      "Wall time: 15min 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jing/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:6: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clfxbf, Xtrain, ytrain, Xtest, ytest = do_classify(GradientBoostingClassifier(),\n",
    "                                                   {\"learning_rate\": [0.05 ,0.1, 0.2],\n",
    "                                                    \"max_depth\":[3,5,10]}, \n",
    "                                                   gram_train_df,t_train,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_test=clfxbf.predict(gram_test_df)\n",
    "write_predictions(t_test,test_ids,\"gbc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
